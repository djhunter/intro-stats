---
title: "Chapter 24: Inference for linear regression, continued"
output: 
  revealjs::revealjs_presentation:
    fig_width: 14 
    fig_height: 7
    self_contained: true
    theme: night
    highlight: zenburn
    css: slidesdjh.css
    center: false
    transition: slide
    reveal_options:
      controls: true
      progress: false
      width: 1080
      height: 540
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
options(width = 100)
library(tidyverse)
library(openintro)
library(kableExtra)
theme_set(theme_bw())
set.seed(1423)
```

# Overview

- 24.4 Mathematical model for testing the slope
    - 24.4.1 Observed data
    - 24.4.2 Variability of the statistic
    - 24.4.3 Observed statistic vs. null statistics
- 24.5 Mathematical model, interval for the slope
    - 24.5.1 Observed data
    - 24.5.2 Variability of the statistic
- 24.6 Checking model conditions
    - 24.6.1 What are the technical conditions for the mathematical model?
    - 24.6.2 Why do we need technical conditions?
    - 24.6.3 What if all the technical conditions are met?

# Last time: regression inference

- Linear regression model: $y = \beta_0 + \beta_1x + \varepsilon$
- Regression equation: $\hat{y} = b_0 + b_1x$
- $b_0$ and $b_1$ are *statistics*.
    - $b_0$ is our best guess for the parameter $\beta_0$
    - $b_1$ is our best guess for the parameter $\beta_1$
- Null Hypothesis: No linear association
    - $H_0: \beta_1 = 0$
        - Regression slope is zero
    - $H_A: \beta_1 \neq 0$
        - Some linear association
        
## Randomization test for regression slope

- You have $n$ observations of two numeric variables, explanatory and response.
- Write the values of the response variable on $n$ cards.
- Shuffle, then randomly pair up with values of the explanatory variable.
- Compute a shuffled $b_1$. (lots)
- Make a null distribution.
- Get a p-value.


##  {data-background="https://openintro-ims.netlify.app/24-inf-model-slr_files/figure-html/permweightScatter-1.png" data-background-size="contain"}

##  {data-background="https://openintro-ims.netlify.app/24-inf-model-slr_files/figure-html/permweekslm-1.png" data-background-size="contain"}

##  {data-background="https://openintro-ims.netlify.app/24-inf-model-slr_files/figure-html/nulldistBirths-1.png" data-background-size="contain"}

# 24.4 Mathematical model for testing the slope

- We can get a $T$-statistic from the *correlation coefficient* $r$.
- This will have a $t$-distribution with $n-2$ degrees of freedom.
- Usually we will use software to get the $t$-statistic and P-value.

\[
T = \frac{r}{\sqrt{\frac{1-r^2}{n-2}}} = \frac{b_1 - 0}{SE_{b_1}}
\]

## 24.4.1 Observed data

- Midterm elections from 1898 to 2018.
- Explanatory: unemployment rate
- Response: percent change in House for president's party

**Research Question:** Can the unemployment rate predict how the president's party will do in the midterm elections?

## House-Midterms data set

```{r}
glimpse(midterms_house)
```

## Scatterplot and Regression Line

```{r, message=FALSE, fig.width=5, fig.height=4, fig.align='center'}
ggplot(midterms_house, aes(x=unemp, y=house_change)) + 
  geom_point() +
  geom_smooth(method=lm)
```

## Influential Outliers

- There are two very influential outliers (high unemployment)
- These both took place during the depression:

```{r}
midterms_house %>% filter(unemp > 15)
```

## Remove outliers and replot

```{r, message=FALSE, fig.width=5, fig.height=4, fig.align='center'}
midhouse_nodep <- midterms_house %>% filter(unemp < 15)
ggplot(midhouse_nodep, aes(x=unemp, y=house_change)) + 
  geom_point() +
  geom_smooth(method=lm)
```

## 24.4.2 Variability of the statistic

```{r}
summary(lm(house_change ~ unemp, data = midhouse_nodep))
```

The data do not show much evidence that unemployment rate is associated with gains/losses in the midterm elections.

# Breakfast Cereal Ratings

Several variables were recorded on 74 different breakfast cereals: number of calories per serving, grams of protein, grams of fat, milligrams of sodium, grams of fiber, grams of carbohydrates, grams of sugars, milligrams of potassium, typical percentage of the FDA's RDA of vitamins, the weight of one serving, the number of cups in one serving, and the shelf location (1,2 or 3 for bottom, middle or top). A variable named "rating" was calculated by Consumer Reports.

## Sugar and Cereal Rating 

Is there a linear relationship between the sugar content of a cereal and its rating?

- Null Hypothesis: There is no association between sugar content and rating.
    + $H_0: \beta_1 = 0$
- Alternative Hypothesis: There is a linear relationship between between sugar content and rating.
    + $H_A: \beta_1 \neq 0$ 

## Group Activity

1. Paste the [CerealSugar](http://math.westmont.edu/data/cerealsugar.txt) data into the [Applet](http://www.rossmanchance.com/applets/RegShuffle.htm?hideExtras=2) and record the correlation coefficient $r$.

2. Find the $T$-statistic using the following formula.
\[
t = \frac{r}{\sqrt{\frac{1-r^2}{n-2}}} 
\]

3. Run a simulation with 1000 shuffles. Select *t-statistic*, then check the *Overlay t distribution* button. Does the t-distribution appear to do a good job of predicting the distribution of the simulated t-statistics? 

4. In the applet, click the box for *Regression Table*. This table provides the observed $T$-statistic for the data as well as the two-sided, theory-based test P-value. Compare the $T$-statistic to the value you calculated in #2. Record the P-value, along with an interpretation of its meaning in context.

## Regression table using R

```{r}
cerealsugar <- read.table("http://math.westmont.edu/data/cerealsugar.txt", header = TRUE)
summary(lm(rating ~ sugars, data = cerealsugar))
```

# 24.5 Mathematical model, interval for the slope

## 24.5.1 Observed data

You need:

- The point estimate $b_1$
- The standard error $SE$
    - Usually you use software to get this.
- $t^\star_{df}$
    - $df = n - 2$
    - The confidence level determines the tail probabilities.
    
$$
\text{point estimate} \pm t^\star_{df} \times SE
$$

## Example: College Gift Aid

```{r}
glimpse(elmhurst)
```

## Scatterplot and Regression Line

```{r, message=FALSE, fig.width=5, fig.height=4, fig.align='center'}
ggplot(elmhurst, aes(x=family_income, y=gift_aid)) + 
  geom_point() +
  geom_smooth(method=lm)
```

## Regression Model

```{r}
summary(lm(gift_aid ~ family_income, data = elmhurst))
```

## Compute a confidence interval

```{r echo=FALSE}
mod1 <- lm(gift_aid ~ family_income, data = elmhurst)
summary(mod1)$coefficients
```

- $SE_{b_1} \approx 0.0108$
- $df = 48$
- $b_1 \approx -0.0431$
- To obtain $t^\star_{48}$, we have to use `qt`. We want a 95% confidence interval.

```{r}
qt(0.975, df = 48)
```

95% CI for $\beta_1$: $-0.0431 \pm 2.01 \times 0.0108 \approx (-0.0648, -0.0214)$

## Group Activity

Recall the regression model for predicting cereal rating (in points) from sugar content (in grams).

```{r echo=FALSE}
summary(lm(rating ~ sugars, data = cerealsugar))$coefficients
```

1. Compute a 90% confidence interval for the regression slope.

2. Write a sentence interpreting this confidence interval in the context of the study.


# 24.6 Checking model conditions

- Every mathematical model is based on theorems that assume that our data has certain properties.
- The P-values and confidence intervals that we compute using mathematical models are not guaranteed to be correct unless these conditions are met.


## 24.6.1 What are the technical conditions for the mathematical model?


>- **Linearity.** The data should show a linear trend. 
>- **Independent observations.** The ordered pairs describe independent observations (e.g., from a random sample).
>- **Nearly normal residuals.** Generally, the residuals must be nearly normal. 
>- **Constant or equal variability.** The variability of points around the least squares line remains roughly constant. 

## {data-background="https://openintro-ims.netlify.app/24-inf-model-slr_files/figure-html/whatCanGoWrongWithLinearModel-1.png" data-background-size="contain"}

## Plotting residuals versus fitted

```{r, message=FALSE, fig.width=5, fig.height=4, fig.align='center'}
cerealmodel <- lm(rating ~ sugars, data = cerealsugar)
ggplot(cerealmodel, aes(x = .fitted, y = .resid)) + geom_point()
```

## More diagnostic plots

```{r, message=FALSE, fig.width=8, fig.height=4, fig.align='center'}
library(ggfortify)
autoplot(cerealmodel)
```


## Failures to meet the conditions

<div class="column-left">
- Data is *not symmetric* above and below the line:

```{r, echo=FALSE, fig.width=4, fig.height=3, fig.align='center', message=FALSE}
library(ggplot2)
sleepgpa <- read.table("http://www.isi-stats.com/isi/data/chap10/SleepGPA.txt", header = TRUE)
ggplot(sleepgpa, aes(x=Sleep, y=GPA)) + geom_point() +geom_smooth(method=lm, se=FALSE)
```
</div>

<div class="column-right">
- Data doesn't follow a linear pattern:

```{r, echo=FALSE, fig.width=4, fig.height=3, fig.align='center', message=FALSE}
library(ggplot2)
examtimes <- read.table("http://www.isi-stats.com/isi/data/chap10/StroopAgeTime.txt", header = TRUE)
ggplot(examtimes, aes(x=Age, y=time)) + geom_point() +geom_smooth(method=lm, se=FALSE)
```
</div>

## More Failures

Variability of vertical slices changes (heteroscedasticity):


<div class="column-left">
```{r, echo=FALSE, fig.width=4, fig.height=3, fig.align='center', message=FALSE}
library(ggplot2)
tvlife <- read.table("http://www.isi-stats.com/isi/data/chap10/TVLife.txt", header = TRUE)
ggplot(tvlife, aes(x=TVsperK, y=LifeExpectancy)) + geom_point() +geom_smooth(method=lm, se=FALSE)
```
</div>

<div class="column-right">
```{r, echo=FALSE, fig.width=4, fig.height=3, fig.align='center', message=FALSE}
library(ggplot2)
smoke <- read.table("http://www.isi-stats.com/isi/data/chap10/AlcoholSmoke.txt", header = TRUE)
ggplot(smoke, aes(x=Alcohol_Drinks, y=Smoked)) + geom_point() +geom_smooth(method=lm, se=FALSE)
```
</div>

## What to do when conditions fail

- What do you do when validity conditions aren’t met for theory-based inference?
    + If it's not too bad, the theory-based tests are probably OK
    + Use the simulation-based approach...
        + *instead of* the theory-based test, for really bad failures 
        + or *in addition to* the theory-based test, in borderline cases
- Another strategy is to “transform” the data on a different scale so conditions are met.  
    + The logarithmic scale is common
    


