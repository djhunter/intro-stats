---
title: "Chapter 16: Inference for a Single Proportion"
output: 
  revealjs::revealjs_presentation:
    fig_width: 14 
    fig_height: 7
    self_contained: true
    theme: night
    highlight: zenburn
    css: slidesdjh.css
    center: false
    transition: slide
    reveal_options:
      controls: true
      progress: false
      width: 1080
      height: 540
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA)
options(width = 100)
library(tidyverse)
library(openintro)
library(kableExtra)
theme_set(theme_bw())
set.seed(1423)
```

# Overview

- 16.1 Bootstrap test for a proportion
    - 16.1.1 Observed data
    - 16.1.2 Variability of the statistic
    - 16.1.3 Observed statistic vs. null statistics
- 16.2 Mathematical model for a proportion
    - 16.2.1 Conditions
    - 16.2.2 Confidence interval for a proportion
    - 16.2.3 Variability of the sample proportion
    - 16.2.4 Changing the confidence level
    - 16.2.5 Hypothesis test for a proportion
    - 16.2.6 Violating conditions

# 16.1 Bootstrap test for a proportion

Two types of bootstrap:

>- **Data Bootstrap:** Observe $\hat{p}$ from a sample of size $n$. Resample the data *with replacement* to generate lots of samples of size $n$, and compute lots of bootstrapped sample proportions.
>    - This is the same as drawing samples of size $n$ using a "spinner" with a success probability of $\hat{p}$.
>    - Use the Data Bootstrap for *confidence intervals*.
>- **Parametric Bootstrap:** Hypothesize $H_0: p = p_0$. Generate lots of samples of size $n$ from an infinite population with a proportion $p_0$ of successes, and compute lots of bootstrapped sample proportions.
>    - This is the same as drawing samples of size $n$ using a "spinner" with a success probability of $p_0$.
>    - Use the Parametric Bootstrap for *hypothesis tests*.

## 16.1.1 Observed data

- Suppose we observe a sample of 25 frogs and discover that 14 are infected with a fungal disease ($\hat{p} = 14/25 = 0.56$). 
- We use the `rbinom` function to draw 10000 samples of size 25 using a "spinner" with success probability of 0.56.

```{r}
bootPhats <- rbinom(10000, 25, 0.56)/25
quantile(bootPhats, c(0.025, 0.975))
```

We are 95% confident that the true proportion of frogs in this population who have this disease is between 0.36 and 0.76.

## Data Bootstrapped Distribution

95% of the bootstrapped proportions are between 0.36 and 0.76.

```{r echo=FALSE, fig.align='center', fig.width=10, fig.height=3}
data.frame(p_hat = bootPhats) %>%
  ggplot(aes(x = p_hat)) +
  geom_histogram(binwidth = 0.05) +
  scale_x_continuous(breaks = c(0.36, 0.56, 0.76))
```

## Hypothesis test with a parametric bootstrap

- Suppose we observe a sample of 25 frogs and discover that 14 are infected with a fungal disease ($\hat{p} = 14/25 = 0.56$). 
- We test $H_0: p = 0.5$ versus $H_A: p>0.5$.

```{r}
bootPhats <- rbinom(10000, 25, 0.5)/25
sum(bootPhats >= 0.56)/10000
```

The p-value of 0.34 tells us that we do not have enough evidence to conclude that the population proportion of frogs with this disease is greater than 0.5.

## Parametric Bootstrapped Distribution

0.34 of the bootstrapped proportions are as or more extreme as 0.56.

```{r echo=FALSE, fig.align='center', fig.width=10, fig.height=3}
data.frame(p_hat = bootPhats) %>%
  ggplot(aes(x = p_hat)) +
  geom_histogram(binwidth = 0.05) +
  scale_x_continuous(breaks = c(0.25, 0.50, 0.56, 0.75))
```

. . . 

**Group Question:** Estimate the endpoints of an interval covering the middle 95% of this distribution. (One sig-fig is OK.) The margin of error of this interval should be two standard errors. Estimate the standard error.

## 16.1.2 Variability of the statistic

The *standard error* of a statistic is the standard deviation of its sampling distribution.

```{r}
sd(bootPhats)
```
We can convert the observed $\hat{p} = 0.56$ to a Z-score:

$$
Z = \frac{\hat{p} - p_0}{SE_{\hat{p}}} \approx \frac{0.56 - 0.5}{0.099899} \approx 0.6
$$

A Z-score of 0.6 isn't very unusual (not much evidence against $H_0$).


# 16.2 Mathematical model for a proportion

- These simulated bootstrap distributions are valuable because they tell us *the variability of the statistic*.
- We can use a mathematical model to tell us the same thing, as long as certain conditions are met.

## 16.2.1 Conditions

By the Central Limit Theorem for Proportions, the sampling distribution for $\hat{p}$ based on a sample of size $n$ from a population with a true proportion $p$ is approximately normal when:

1. The sample's observations are *independent*, e.g., are from a simple random sample.

2. We expect to see at least 10 successes and 10 failures in the sample, i.e., $np \geq 10$ and $n(1-p) \geq 10$. This is called the *success-failure condition*.

## General formula for standard error

If the independence and success-failure conditions are met,

$$
SE_\hat{p} \approx \sqrt{\frac{(\mbox{best guess of }p)(1 - \mbox{best guess of }p)}{n}}
$$

- For confidence intervals, the "best guess" of $p$ is the observed $\hat{p}$.
- For hypothesis tests with $H_0: p = p_0$, the "best guess" of $p$ is $p_0$.

## 16.2.2 Confidence interval for a proportion

- Suppose we observe a sample of 25 frogs and discover that 14 are infected with a fungal disease ($\hat{p} = 14/25 = 0.56$). 
    - We have 14 successes and 11 failures $\checkmark$

$$
SE_\hat{p} \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \approx \sqrt{\frac{0.56(1-0.56)}{25}} \approx 0.0993
$$

So the quick 95% confidence interval is:

$$
\hat{p} \pm 1.96 \times SE_{\hat{p}} \approx 0.56 \pm 1.96\times0.0993 \approx 0.56\pm 0.195 \approx (0.37, 0.75)
$$

## Group Activity

A simple random sample of 826 payday loan borrowers was surveyed to better understand their interests around regulation and costs. 70% of the responses supported new regulations on payday lenders.

1. Check that the conditions are satisfied to use the normal approximation.

2. Estimate the standard error of $\hat{p}$.

3. Construct a 95% confidence interval for $p$, the proportion of payday borrowers who support increased regulation for payday lenders.

4. If we increased the confidence level from 95% to 99%, how would the confidence interval change (wider, narrower, same)?

5. If the sample size were 2000 instead of 826, how would the confidence interval change (wider, narrower, same)?

## Setting the sample size

How big a sample do you need?

- Decide on a margin of error.
- The standard error is about half the margin of error (for a 95% confidence interval).
- Solve the equation for $n$: 
$$
SE_\hat{p} \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
$$
 
## 16.2.5 Hypothesis test for a proportion

- Suppose we observe a sample of 25 frogs and discover that 14 are infected with a fungal disease ($\hat{p} = 14/25 = 0.56$). 
- Test the hypotheses $H_0: p = 0.5$ versus the alternative $H_A: p > 0.5$.

$$
SE_\hat{p} \approx \sqrt{\frac{p_0(1-p_0)}{n}} \approx \sqrt{\frac{0.5(1-0.5)}{25}} = 0.1
$$

$$
Z = \frac{\hat{p} - p_0}{SE_{\hat{p}}} = \frac{0.56 - 0.5}{0.1} = 0.6
$$

A Z-score of 0.6 is not much evidence against $H_0$.

```{r}
pnorm(0.6, lower.tail = FALSE)
```

## Group Activity

A simple random sample of 826 payday loan borrowers found that 55% of those surveyed think interest rates are too high. Does this survey indicate that a majority of borrowers think interest rates are too high?

1. Write null and alternative hypotheses in symbols. (Use a 1-sided alternative.)

2. Compute $SE_\hat{p}$ using the null value of $p$.

3. Compute a Z-score.

4. Use `pnorm` to compute a p-value.

5. How would the p-value be different if we used a two-sided alternative?


## 16.2.6 Violating conditions

- If the success-failure condition fails, use a simulation-based test (e.g., bootstrapping).
- If the independence condition fails, more advanced techniques are required.


